Start(sec),Duration(nsec),CorrId,GrdX,GrdY,GrdZ,BlkX,BlkY,BlkZ,Reg/Trd,StcSMem,DymSMem,Bytes,Thru(MB/s),SrcMemKd,DstMemKd,Device,Ctx,Strm,Name
12.944439,2400,132,,,,,,,,,,6912,2880.000,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.944720,1697,144,,,,,,,,,,256,150.854,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.944898,27327,156,,,,,,,,,,294912,10791.964,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.945000,1728,168,,,,,,,,,,512,296.296,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.945581,110271,184,,,,,,,,,,1179648,10697.717,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.945921,1760,196,,,,,,,,,,1024,581.818,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.946233,369757,208,,,,,,,,,,2359296,6380.666,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.946896,1920,220,,,,,,,,,,1024,533.333,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.947204,929563,232,,,,,,,,,,4718592,5076.140,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.948331,2176,244,,,,,,,,,,2048,941.176,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.948638,2109044,256,,,,,,,,,,9437184,4474.626,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.951061,2144,268,,,,,,,,,,2048,955.224,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.951712,2040181,284,,,,,,,,,,9437184,4625.660,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.953971,1888,296,,,,,,,,,,2048,1084.746,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.954299,2037941,308,,,,,,,,,,9437184,4630.744,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.956640,1920,320,,,,,,,,,,2048,1066.667,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
12.957623,95011108,336,,,,,,,,,,411041792,4326.250,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
13.053925,3456,348,,,,,,,,,,16384,4740.741,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
13.054846,15319374,364,,,,,,,,,,67108864,4380.653,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
13.070797,3712,376,,,,,,,,,,16384,4413.793,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
13.071547,3605452,392,,,,,,,,,,16384000,4544.229,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
13.075632,2112,404,,,,,,,,,,4000,1893.939,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
15.776257,787644,443,,,,,,,,,,9633792,12231.150,Pinned,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
15.777049,4448,455,,,,,,,,,,128,28.777,Pinned,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
15.804086,1888,617,,,,,,,,,,15360,8135.593,Device,,Tesla V100-SXM2-16GB (0),1,21,[CUDA memset]
15.804140,1632,619,,,,,,,,,,15360,9411.765,Device,,Tesla V100-SXM2-16GB (0),1,22,[CUDA memset]
15.804166,1599,620,,,,,,,,,,15360,9606.004,Device,,Tesla V100-SXM2-16GB (0),1,23,[CUDA memset]
15.804193,1632,621,,,,,,,,,,15360,9411.765,Device,,Tesla V100-SXM2-16GB (0),1,24,[CUDA memset]
15.805036,1888,652,,,,,,,,,,112,59.322,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
15.871098,8512,852,197,1,1,256,1,1,38,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)
15.871154,375294,853,6272,1,1,128,1,1,128,16384,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_scudnn_128x64_relu_small_nn_v1
15.871531,508733,857,200704,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.872041,498845,863,200704,1,1,64,1,1,18,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.876486,440702,880,50176,1,1,256,1,1,26,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.882608,244478,900,49,64,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.882854,5952,901,2,16,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.882862,715708,909,392,1,36,256,1,1,57,16384,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_32x128_nn
15.883579,405886,911,49,128,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.883986,252991,916,100352,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.884240,250143,922,100352,1,1,64,1,1,18,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.884491,220190,931,25088,1,1,256,1,1,26,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.884713,135232,943,16,128,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.884849,8767,944,4,32,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.884859,626556,952,49,4,36,64,1,1,126,8448,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nn
15.885487,212863,954,16,256,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.885701,127999,959,50176,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.885830,126272,965,50176,1,1,64,1,1,18,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.886212,249247,982,16,256,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.886462,15328,983,8,32,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.886479,1188826,991,49,4,36,64,1,1,126,8448,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nn
15.887669,211998,993,16,256,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.887882,128576,998,50176,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.888011,126527,1004,50176,1,1,64,1,1,18,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.888139,112511,1013,12544,1,1,256,1,1,26,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.888252,62112,1025,4,256,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.888316,32480,1026,8,64,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.888350,642204,1034,25,4,36,256,1,1,57,16384,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_32x128_nn
15.888993,135264,1036,4,512,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.889129,66335,1041,25088,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.889196,64031,1047,25088,1,1,64,1,1,18,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.889261,133855,1060,4,512,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.889396,65056,1061,16,64,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.889463,1248537,1069,25,4,36,256,1,1,57,16384,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_32x128_nn
15.890712,135392,1071,4,512,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.890849,66400,1076,25088,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.890916,64128,1082,25088,1,1,64,1,1,18,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.890981,59327,1091,6272,1,1,256,1,1,26,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.891042,36736,1103,1,512,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.891079,65824,1104,16,64,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.891146,427773,1112,4,8,36,64,1,1,126,8448,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nn
15.891575,36225,1114,1,512,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.891612,16448,1119,6272,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.891630,12416,1125,6272,1,1,64,1,1,18,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.891643,34528,1138,1,512,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.891685,65248,1139,16,64,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.891751,426782,1147,4,8,36,64,1,1,126,8448,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nn
15.892179,36192,1149,1,512,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.892216,15904,1154,6272,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.892233,12512,1160,6272,1,1,64,1,1,18,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.892247,14848,1169,1568,1,1,256,1,1,26,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.892263,60096,1181,8192,1,1,32,8,1,40,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::adaptive_average_pool<float>(float*, float*, int, int, int, int, long, long, long)"
15.892325,6497,1188,256,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.892367,2400,1209,,,,,,,,,,112,46.667,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
15.898737,743132,1356,64,1,15,256,1,1,82,26624,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x32_sliced1x4_tn
15.899482,8480,1358,512,1,1,128,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
15.899491,1952,1365,256,1,1,64,1,1,18,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.899494,3936,1392,256,1,1,256,1,1,48,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<unsigned char, unsigned int>, unsigned int, float, at::PhiloxCudaState)"
15.899512,3264,1399,256,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.899608,142847,1408,64,1,6,256,1,1,82,26624,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x32_sliced1x4_tn
15.899752,4704,1410,512,1,1,128,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
15.899758,1920,1417,256,1,1,64,1,1,18,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.899823,2720,1444,256,1,1,256,1,1,48,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<unsigned char, unsigned int>, unsigned int, float, at::PhiloxCudaState)"
15.899921,2784,1451,63,1,1,64,1,1,22,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.899991,39007,1460,16,1,8,256,1,1,82,26624,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x32_sliced1x4_tn
15.900031,2720,1462,125,1,1,128,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
15.900342,8223,1472,4,1,1,32,4,1,80,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)"
15.907577,4512,1485,1,1,1,32,1,1,34,256,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)"
15.907968,24448,1493,16,1,1,1024,1,1,32,128,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::gatherTopK<float, unsigned int, 2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, unsigned int, unsigned int, at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, at::cuda::detail::TensorInfo<long, unsigned int>, unsigned int)"
15.908084,9792,1496,16,1,1,16,1,1,30,416,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::bitonicSortKVInPlace<float, long, 2, -1, GTComp<float, true>, unsigned int, 32>(at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, unsigned int, at::cuda::detail::TensorInfo<long, unsigned int>, unsigned int, GTComp<float, true>)"
15.908406,3776,1509,1,1,1,64,1,1,28,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::CompareEqFunctor<long>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::CompareEqFunctor<long>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.908582,4448,1520,1,1,1,64,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast)"
15.908763,5120,1533,1,1,1,16,1,1,30,16,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.909002,1664,1539,1,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.909108,4000,1550,1,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#22}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#22}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.909207,4160,1563,1,1,1,64,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast)"
15.909290,2880,1576,1,1,1,64,1,1,30,16,256,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.909352,1216,1582,1,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.909479,3072,1589,,,,,,,,,,4,1.302,Device,Pageable,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoH]
15.909686,1249,1599,1,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.909805,1696,1606,1,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2>)"
15.909897,1248,1612,1,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.909972,1248,1621,1,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.910014,1216,1628,1,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2>)"
15.910067,1215,1634,1,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.910668,1344,1646,1,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.912302,1664,1658,,,,,,,,,,64000,38461.538,Device,,Tesla V100-SXM2-16GB (0),1,7,[CUDA memset]
15.912338,2624,1662,1,1,1,32,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)"
15.912486,9056,1674,4,1,1,32,4,1,109,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)"
15.912697,2079,1700,,,,,,,,,,112,53.872,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
15.917204,44448,1846,128,1,1,128,1,1,86,32768,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_32x32_sliced1x4_nn
15.917376,31169,1856,32,32,1,256,1,1,57,16384,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_128x32_nt
15.917479,7712,1867,2,1,1,32,4,1,52,16,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.917670,2656,1883,256,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3>)"
15.917825,2592,1891,256,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.917965,132704,1905,64,1,6,256,1,1,82,25600,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x32_sliced1x4_nn
15.918099,5600,1907,512,1,1,128,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
15.918106,90400,1918,32,128,1,256,1,1,57,16384,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_128x32_nt
15.918198,8800,1929,8,1,1,32,4,1,52,16,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.918258,2112,1945,256,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3>)"
15.918300,2335,1953,256,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.918419,642428,1965,196,1,1,256,1,1,134,41984,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_128x32_sliced1x4_nn
15.919895,598205,1979,196,64,1,128,1,1,122,12288,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_128x64_nt
15.920494,6368,1990,8,1,1,32,4,1,52,16,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.920502,4128,2010,1568,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.920508,45536,2015,8192,1,1,32,8,1,30,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::atomic_adaptive_average_gradinput<float>(float*, float*, int, int, int, int)"
15.920555,11359,2025,6272,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.920568,44608,2032,1,16,512,256,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.920614,23456,2040,6272,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.920638,28768,2054,32,1,1,32,16,1,30,16,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.921131,1888,2105,,,,,,,,,,15360,8135.593,Device,,Tesla V100-SXM2-16GB (0),1,33,[CUDA memset]
15.921156,1568,2106,,,,,,,,,,15360,9795.918,Device,,Tesla V100-SXM2-16GB (0),1,34,[CUDA memset]
15.921171,1600,2107,,,,,,,,,,15360,9600.000,Device,,Tesla V100-SXM2-16GB (0),1,35,[CUDA memset]
15.921183,1568,2108,,,,,,,,,,15360,9795.918,Device,,Tesla V100-SXM2-16GB (0),1,36,[CUDA memset]
15.921360,2080,2139,,,,,,,,,,112,53.846,Pageable,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy HtoD]
15.925711,32576,2289,1,512,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.925745,61791,2290,16,64,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.925843,427966,2298,4,8,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.926272,37376,2300,1,512,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.931406,37920,2315,32,16,1,256,1,1,64,24704,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.931446,33504,2316,32,16,1,256,1,1,64,16896,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
15.931482,427838,2324,8,8,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.931911,64191,2326,16,64,1,32,8,1,62,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
15.931977,24896,2337,6272,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.932002,27296,2351,32,1,1,32,16,1,30,16,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.932031,32736,2370,1,512,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.932065,66112,2371,16,64,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.932132,424477,2379,4,8,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.932557,34752,2381,1,512,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.932593,36032,2395,32,16,1,256,1,1,64,24704,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.932630,36224,2396,32,16,1,256,1,1,64,16896,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
15.932667,399869,2404,8,8,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.933068,61215,2406,16,64,1,32,8,1,62,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
15.933130,42784,2419,25088,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.933174,153823,2426,4,16,512,256,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.933329,93183,2434,25088,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.933423,44480,2447,512,1,1,32,16,1,30,16,2048,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.934303,129535,2470,4,512,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.934433,65440,2471,16,64,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.934500,1195097,2479,25,4,36,256,1,1,57,16384,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_32x128_nt
15.935696,133216,2481,4,512,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.935830,120095,2495,128,16,1,256,1,1,64,24704,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.935951,126527,2496,128,16,1,256,1,1,64,16896,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
15.936079,1186681,2504,8,8,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.937267,61696,2506,16,64,1,32,8,1,62,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
15.937330,93279,2517,25088,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.937424,44416,2530,512,1,1,32,16,1,30,16,2048,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.937470,127423,2549,4,512,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.937598,31488,2550,8,64,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.937630,624797,2558,25,2,36,256,1,1,57,16384,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_32x128_nt
15.938256,67072,2560,4,256,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.938324,59360,2574,64,16,1,256,1,1,64,24704,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.938385,120831,2575,128,16,1,256,1,1,64,16896,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
15.938506,639421,2583,4,8,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.939147,31488,2585,8,64,1,32,8,1,62,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
15.939180,83583,2598,50176,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.939265,289407,2605,13,16,256,256,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.939556,183839,2613,50176,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.939741,73375,2626,256,1,1,32,16,1,30,16,2048,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.939816,248927,2649,16,256,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.940065,15072,2650,8,32,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.940081,1178841,2658,49,4,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.941261,210975,2660,16,256,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.941473,248063,2674,224,16,1,256,1,1,64,24704,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.941722,252607,2675,224,16,1,256,1,1,64,16896,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
15.941976,1258809,2683,4,4,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.943235,16512,2685,8,32,1,32,8,1,62,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
15.943253,182943,2696,50176,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.943437,72032,2709,256,1,1,32,16,1,30,16,2048,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.943510,243070,2728,16,256,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.943754,8768,2729,4,32,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.943764,607421,2737,49,2,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.944374,112800,2739,16,128,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.944487,124544,2753,112,16,1,256,1,1,64,24704,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.944613,249791,2754,224,16,1,256,1,1,64,16896,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
15.944864,629181,2762,4,2,36,256,1,1,57,16384,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_32x128_nt
15.945495,7136,2764,4,32,1,32,8,1,62,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
15.945503,165535,2777,100352,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.945670,566877,2784,49,16,128,256,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.946238,364062,2792,100352,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.946604,2432,2807,,,,,,,,,,512,210.526,Device,,Tesla V100-SXM2-16GB (0),1,7,[CUDA memset]
15.946609,150943,2809,128,3,1,32,16,1,30,16,2048,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.946761,477182,2832,49,128,1,256,1,1,64,22656,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.947239,4255,2833,2,16,1,32,8,1,32,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)"
15.947245,615452,2841,196,1,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.947861,205919,2843,49,64,1,256,1,1,64,16640,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)"
15.948068,232799,2857,196,16,1,256,1,1,64,24704,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)"
15.948302,496701,2858,392,16,1,256,1,1,64,16896,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)"
15.948800,1383801,2866,1,2,36,64,1,1,126,8192,0,,,,,Tesla V100-SXM2-16GB (0),1,7,volta_sgemm_64x64_nt
15.950185,3744,2868,2,16,1,32,8,1,62,9216,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)"
15.950189,329630,2881,200704,1,1,64,1,1,16,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.950520,1131802,2888,196,16,64,256,1,1,32,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.951653,725052,2896,200704,1,1,64,1,1,19,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.952380,1696,2911,,,,,,,,,,256,150.943,Device,,Tesla V100-SXM2-16GB (0),1,7,[CUDA memset]
15.952384,274494,2913,64,7,1,32,16,1,30,16,2048,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.952660,1985,2934,,,,,,,,,,6912,3482.116,Device,,Tesla V100-SXM2-16GB (0),1,7,[CUDA memset]
15.952663,798811,2935,1,2,1568,8,8,1,96,3328,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
15.963273,2048,2953,7,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963402,1664,2964,,,,,,,,,,6912,4153.846,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.963473,1344,2969,7,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963506,1408,2975,1,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963534,1216,2986,,,,,,,,,,256,210.526,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.963564,1248,2991,1,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963605,2432,2997,288,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963663,1728,3008,,,,,,,,,,294912,170666.667,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.963718,1824,3013,288,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963747,1504,3019,1,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963784,1248,3030,,,,,,,,,,512,410.256,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.963826,1440,3035,1,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963844,4832,3041,1152,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963876,3168,3052,,,,,,,,,,1179648,372363.636,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.963908,3232,3057,1152,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963924,1472,3063,1,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963947,1216,3074,,,,,,,,,,1024,842.105,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.963964,1312,3079,1,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.963979,10912,3085,2304,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964014,4256,3096,,,,,,,,,,2359296,554345.865,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.964033,6977,3101,2304,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964048,1920,3107,1,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964068,1215,3118,,,,,,,,,,1024,842.798,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.964094,1279,3123,1,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964111,18400,3129,4608,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964135,12192,3140,,,,,,,,,,4718592,387023.622,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.964153,16928,3145,4608,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964171,1696,3151,2,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964201,1280,3162,,,,,,,,,,2048,1600.000,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.964221,1248,3167,2,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964237,35328,3173,9216,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964273,25760,3184,,,,,,,,,,9437184,366350.311,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.964300,35648,3189,9216,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964336,1536,3195,2,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964340,1600,3206,,,,,,,,,,2048,1280.000,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.964357,1312,3211,2,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964371,35520,3217,9216,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964408,25823,3228,,,,,,,,,,9437184,365456.531,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.964434,35392,3233,9216,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964471,1792,3239,2,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964475,1280,3250,,,,,,,,,,2048,1600.000,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.964479,1312,3255,2,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964505,35200,3261,9216,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964541,25920,3272,,,,,,,,,,9437184,364088.889,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.964568,35552,3277,9216,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964604,1728,3283,2,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.964607,1280,3294,,,,,,,,,,2048,1600.000,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.964610,1311,3299,2,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.965622,1447320,3309,401408,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.967071,1043003,3324,,,,,,,,,,411041792,394094.544,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.968115,1447000,3329,401408,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.969562,2560,3335,16,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.969566,1312,3346,,,,,,,,,,16384,12487.805,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.969568,1280,3351,16,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.969572,239199,3357,65536,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.969812,172511,3368,,,,,,,,,,67108864,389012.086,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.969985,238431,3373,65536,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.970225,2111,3379,16,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.970228,1344,3390,,,,,,,,,,16384,12190.476,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.970230,1280,3395,16,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.970233,59999,3401,16000,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.970294,43712,3412,,,,,,,,,,16384000,374816.984,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.970338,60320,3417,16000,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.970400,2208,3423,4,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.970403,1344,3434,,,,,,,,,,4000,2976.190,Device,Device,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoD]
15.970406,1344,3439,4,1,1,64,1,1,20,0,0,,,,,Tesla V100-SXM2-16GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.970412,3583,3445,,,,,,,,,,4,1.116,Device,Pageable,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoH]
15.970544,2368,3452,,,,,,,,,,4,1.689,Device,Pageable,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoH]
15.970629,1984,3459,,,,,,,,,,4,2.016,Device,Pageable,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoH]
15.970684,2016,3466,,,,,,,,,,4,1.984,Device,Pageable,Tesla V100-SXM2-16GB (0),1,7,[CUDA memcpy DtoH]
