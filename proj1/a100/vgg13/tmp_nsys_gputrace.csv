Start(sec),Duration(nsec),CorrId,GrdX,GrdY,GrdZ,BlkX,BlkY,BlkZ,Reg/Trd,StcSMem,DymSMem,Bytes,Thru(MB/s),SrcMemKd,DstMemKd,Device,Ctx,Strm,Name
13.269103,4864,132,,,,,,,,,,6912,1421.053,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.269616,4064,144,,,,,,,,,,256,62.992,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.269779,29664,156,,,,,,,,,,147456,4970.874,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.269897,3840,168,,,,,,,,,,256,66.667,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.270032,53280,180,,,,,,,,,,294912,5535.135,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.270159,5824,192,,,,,,,,,,512,87.912,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.270360,100640,204,,,,,,,,,,589824,5860.731,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.270540,3967,216,,,,,,,,,,512,129.065,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.271136,201985,232,,,,,,,,,,1179648,5840.275,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.271563,4064,244,,,,,,,,,,1024,251.969,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.271880,476354,256,,,,,,,,,,2359296,4952.821,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.272653,4000,268,,,,,,,,,,1024,256.000,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.272963,995267,280,,,,,,,,,,4718592,4741.031,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.274280,4064,292,,,,,,,,,,2048,503.937,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.274599,2095718,304,,,,,,,,,,9437184,4503.079,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.277045,4160,316,,,,,,,,,,2048,492.308,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.277607,2119910,332,,,,,,,,,,9437184,4451.691,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.279956,4064,344,,,,,,,,,,2048,503.937,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.280290,2083366,356,,,,,,,,,,9437184,4529.777,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.282584,4160,368,,,,,,,,,,2048,492.308,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.283531,94403902,384,,,,,,,,,,411041792,4354.076,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.379304,7040,396,,,,,,,,,,16384,2327.273,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.380035,15458479,412,,,,,,,,,,67108864,4341.233,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.395970,7008,424,,,,,,,,,,16384,2337.900,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.396572,3650603,440,,,,,,,,,,16384000,4488.026,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.400641,4256,452,,,,,,,,,,4000,939.850,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.606784,785954,511,,,,,,,,,,9633792,12257.450,Pinned,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.607575,4384,523,,,,,,,,,,128,29.197,Pinned,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.618918,2336,676,,,,,,,,,,20736,8876.712,Device,,NVIDIA A100-SXM4-40GB (0),1,21,[CUDA memset]
15.618939,2208,677,,,,,,,,,,20736,9391.304,Device,,NVIDIA A100-SXM4-40GB (0),1,22,[CUDA memset]
15.618965,2144,678,,,,,,,,,,20736,9671.642,Device,,NVIDIA A100-SXM4-40GB (0),1,23,[CUDA memset]
15.618985,2207,679,,,,,,,,,,20736,9395.560,Device,,NVIDIA A100-SXM4-40GB (0),1,24,[CUDA memset]
15.619456,2176,710,,,,,,,,,,112,51.471,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.677078,542306,2420,25088,2,1,8,8,1,64,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
15.677623,364706,2425,200704,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.677990,296225,2431,200704,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.680159,321249,2452,1568,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.680482,5024,2454,1,2,64,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.680489,960579,2458,1,3136,1,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)"
15.681452,364417,2465,200704,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.681819,296929,2471,200704,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.682117,278817,2480,50176,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.684088,76224,2496,392,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.684166,5120,2498,1,2,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.684224,361250,2502,1,1568,1,128,1,1,236,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.684587,185280,2509,100352,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.684774,151361,2515,100352,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.685796,153537,2536,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.685951,5888,2538,1,4,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.685958,615426,2542,1,1568,1,128,1,1,236,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.686575,184577,2549,100352,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.686762,150721,2555,100352,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.686914,144385,2564,25088,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.687060,39968,2576,98,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.687102,8256,2578,1,4,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.687112,331745,2582,2,392,1,128,1,1,236,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.687446,95457,2589,50176,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.687543,75712,2595,50176,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.687998,77440,2616,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.688077,10720,2618,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.688129,629345,2622,2,196,1,256,1,1,252,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.688760,95809,2629,50176,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.688858,76097,2635,50176,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.688936,75392,2644,12544,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.689087,19296,2660,25,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.689113,16512,2662,1,8,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.689134,321472,2666,4,49,1,256,1,1,252,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.689457,49440,2673,25088,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.689508,27200,2679,25088,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.690238,34688,2700,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.690275,29312,2702,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.690306,597154,2706,4,49,1,256,1,1,252,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.690905,49120,2713,25088,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.690956,26848,2719,25088,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.690985,37376,2728,6272,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.691171,10209,2740,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.691182,29377,2742,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.691287,171937,2746,4,25,1,128,1,1,252,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.691461,14560,2753,6272,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.691477,8384,2759,6272,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.691641,8480,2772,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.691651,28160,2774,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.691681,168736,2778,4,25,1,128,1,1,252,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.691852,14528,2785,6272,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.691868,8415,2791,6272,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.691878,9888,2800,1568,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.692247,52800,2812,8192,1,1,32,8,1,40,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::adaptive_average_pool<float>(float*, float*, int, int, int, int, long, long, long)"
15.692733,4992,2819,256,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.692883,2848,2840,,,,,,,,,,112,39.326,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.696836,2112,4507,,,,,,,,,,128,60.606,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.696877,350753,4510,8,4,3,128,1,1,164,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_32x6_tn_align4>(cutlass_80_tensorop_s1688gemm_128x64_32x6_tn_align4::Params)
15.697229,2720,4517,256,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.697374,4544,4544,256,1,1,256,1,1,31,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<unsigned char, unsigned int>, unsigned int, float, at::PhiloxCudaState)"
15.697524,4704,4551,256,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.697630,62720,4562,8,2,4,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x64_32x3_tn_align4>(cutlass_80_tensorop_s1688gemm_256x64_32x3_tn_align4::Params)
15.697695,4064,4564,512,1,1,128,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
15.697758,2336,4571,256,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.698238,4384,4602,256,1,1,256,1,1,31,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<unsigned char, unsigned int>, unsigned int, float, at::PhiloxCudaState)"
15.698355,4192,4609,63,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.698453,20193,4620,8,2,5,128,1,1,96,0,98304,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4::Params)
15.698475,3711,4622,125,1,1,128,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
15.698835,4640,4632,4,1,1,32,4,1,80,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)"
15.702668,4608,4645,1,1,1,32,1,1,34,256,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)"
15.703014,20768,4653,16,1,1,1024,1,1,32,128,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::gatherTopK<float, unsigned int, 2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, unsigned int, unsigned int, at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, at::cuda::detail::TensorInfo<long, unsigned int>, unsigned int)"
15.703155,7904,4656,16,1,1,16,1,1,25,416,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::bitonicSortKVInPlace<float, long, 2, -1, GTComp<float, true>, unsigned int, 32>(at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, unsigned int, at::cuda::detail::TensorInfo<long, unsigned int>, unsigned int, GTComp<float, true>)"
15.703470,3136,4669,1,1,1,64,1,1,26,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::CompareEqFunctor<long>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::CompareEqFunctor<long>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.703653,3296,4680,1,1,1,64,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast)"
15.703853,4672,4693,1,1,1,16,1,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.704012,2047,4699,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.704134,2816,4710,1,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#22}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#22}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.704240,3072,4723,1,1,1,64,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast)"
15.704281,3456,4736,1,1,1,64,1,1,28,16,256,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.704324,1760,4742,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.704422,3776,4749,,,,,,,,,,4,1.059,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
15.704582,1664,4759,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.704691,1600,4766,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2>)"
15.704761,1537,4772,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.704796,1664,4781,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.704835,1664,4788,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2>)"
15.704853,1664,4794,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.705265,1536,4806,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.706747,2240,4818,,,,,,,,,,64000,28571.429,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.706798,2944,4822,1,1,1,32,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)"
15.706910,5504,4834,4,1,1,32,4,1,107,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)"
15.707089,2688,4860,,,,,,,,,,112,41.667,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.710947,20960,6528,8,8,1,128,1,1,106,0,98304,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4::Params)
15.711102,22432,6539,32,32,1,256,1,1,57,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x32_nt
15.711206,6400,6550,2,1,1,32,4,1,52,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.711388,3104,6566,256,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3>)"
15.711503,3040,6574,256,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.711642,68928,6590,8,2,4,128,1,1,234,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x64_32x3_nn_align4>(cutlass_80_tensorop_s1688gemm_256x64_32x3_nn_align4::Params)
15.711713,3872,6592,512,1,1,128,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
15.712218,57984,6607,32,64,1,128,1,1,122,12288,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x64_nt
15.712306,6207,6618,8,1,1,32,4,1,52,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.712393,3200,6634,256,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3>)"
15.712440,3104,6642,256,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.712521,314465,6657,8,25,1,128,1,1,156,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_32x6_nn_align4>(cutlass_80_tensorop_s1688gemm_128x64_32x6_nn_align4::Params)
15.713394,320064,6671,196,64,1,128,1,1,122,12288,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x64_nt
15.713716,6432,6682,8,1,1,32,4,1,52,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.713725,3328,6702,1568,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.713730,40352,6707,8192,1,1,32,8,1,30,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::atomic_adaptive_average_gradinput<float>(float*, float*, int, int, int, int)"
15.713772,7712,6717,6272,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.713782,40512,6724,1,16,512,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.713824,11552,6732,6272,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.713838,25312,6746,32,1,1,32,16,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.715555,2400,6797,,,,,,,,,,20736,8640.000,Device,,NVIDIA A100-SXM4-40GB (0),1,33,[CUDA memset]
15.715570,2144,6798,,,,,,,,,,20736,9671.642,Device,,NVIDIA A100-SXM4-40GB (0),1,34,[CUDA memset]
15.715584,2208,6799,,,,,,,,,,20736,9391.304,Device,,NVIDIA A100-SXM4-40GB (0),1,35,[CUDA memset]
15.715599,2144,6800,,,,,,,,,,20736,9671.642,Device,,NVIDIA A100-SXM4-40GB (0),1,36,[CUDA memset]
15.715740,2656,6831,,,,,,,,,,112,42.169,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.720813,29088,8505,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.720843,9664,8507,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.720910,181153,8511,4,25,1,128,1,1,254,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.726600,12129,8532,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.726614,12735,8534,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.726640,7392,8536,,,,,,,,,,9438368,1276835.498,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.726663,2656,8537,,,,,,,,,,1152,433.735,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.726696,204288,8540,36,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.726903,26433,8544,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.726931,15840,8555,6272,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.726949,25215,8569,32,1,1,32,16,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.727277,28480,8588,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.727307,9664,8590,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.727319,180544,8594,4,25,1,128,1,1,254,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.727501,12832,8610,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.727515,12832,8612,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.727529,7135,8614,,,,,,,,,,9438368,1322826.629,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.727539,2368,8615,,,,,,,,,,1152,486.486,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.727549,203649,8618,36,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.727755,26368,8622,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.727784,25760,8635,25088,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.727811,139233,8642,4,16,512,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.728081,53376,8654,25088,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.728146,34976,8667,512,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.729490,27808,8690,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.729519,36865,8692,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.729602,611713,8696,2,98,1,256,1,1,242,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.730427,37376,8716,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.730466,40416,8718,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.730508,8289,8720,,,,,,,,,,9438368,1138661.841,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.730519,2304,8721,,,,,,,,,,1152,500.000,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.730525,726787,8724,36,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.731254,26784,8728,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.731282,58624,8739,25088,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.731343,36256,8752,512,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.731381,16192,8771,1,8,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.731399,34624,8773,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.731436,315009,8777,1,98,1,256,1,1,242,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.731828,19649,8793,25,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.731849,40095,8795,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.731891,5089,8797,,,,,,,,,,4719200,927333.464,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.731898,2400,8798,,,,,,,,,,576,240.000,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.731905,374081,8801,18,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.732281,15040,8805,1,8,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.732297,49408,8818,50176,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.732349,259425,8825,13,16,256,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.732610,111168,8833,50176,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.732723,63520,8846,256,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.732789,9952,8865,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.732801,67296,8867,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.732871,619298,8871,2,392,1,128,1,1,238,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.733771,74592,8891,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.733847,76641,8893,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.733926,3551,8895,,,,,,,,,,2359616,664493.382,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.733931,2656,8896,,,,,,,,,,288,108.434,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.733938,728098,8899,18,2,6,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.734668,9376,8903,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.734680,106272,8914,50176,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.734788,64096,8927,256,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.734854,7871,8946,1,4,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.734863,67521,8948,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.734933,340481,8952,1,196,1,256,1,1,254,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)"
15.735276,37728,8968,98,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.735315,76480,8970,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.735393,9568,8972,,,,,,,,,,12977024,1356294.314,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.735405,2304,8973,,,,,,,,,,864,375.000,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.735412,367809,8976,9,2,12,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.735782,16960,8978,9,2,4,128,1,1,64,0,17408,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.735801,5984,8981,1,4,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.735809,96608,8994,100352,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.735907,507585,9001,49,16,128,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.736417,223201,9009,100352,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.736642,2208,9024,,,,,,,,,,512,231.884,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.736648,115136,9026,128,4,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.736765,5216,9045,1,4,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.736772,142593,9047,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.736917,627554,9051,1,1568,1,128,1,1,238,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.737546,150272,9071,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.737698,156000,9073,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.737856,9600,9075,,,,,,,,,,13566848,1413213.333,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.737868,3009,9076,,,,,,,,,,864,287.139,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.737875,716098,9079,9,1,24,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.738593,29408,9081,9,1,4,128,1,1,64,0,17408,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.738624,4192,9084,1,4,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.738631,217568,9095,100352,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.738851,2175,9110,,,,,,,,,,512,235.402,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.738858,114848,9112,128,4,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.738975,4608,9131,1,2,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.738981,143424,9133,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.739126,456354,9137,1,784,1,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.739584,75904,9153,392,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.739662,150240,9155,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.739814,3968,9157,,,,,,,,,,3244496,817665.323,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.739821,2816,9158,,,,,,,,,,432,153.409,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.739827,498882,9161,9,1,12,128,1,1,205,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 3> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 3>::Params)"
15.740329,4256,9165,1,2,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.740335,192225,9178,200704,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.740529,1011875,9185,196,16,64,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.741544,445537,9193,200704,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.741992,3200,9208,,,,,,,,,,256,80.000,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.741999,216481,9210,64,7,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.742218,4576,9229,1,2,64,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.742223,305377,9231,1568,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.742531,1006148,9235,1,3136,1,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.743539,317249,9255,1568,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.743858,321377,9257,1568,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.744181,3007,9259,,,,,,,,,,1622480,539567.675,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.744188,2176,9260,,,,,,,,,,432,198.529,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.744193,1374212,9263,9,1,12,128,1,1,128,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 64, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 64, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 4>::Params)"
15.745570,4096,9267,1,2,64,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.745576,433665,9278,200704,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.746012,2176,9293,,,,,,,,,,256,117.647,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.746017,216257,9295,64,7,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.746236,2240,9316,,,,,,,,,,6912,3085.714,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.746240,482017,9317,1,2,1568,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
15.756144,2528,9335,7,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756259,2080,9346,,,,,,,,,,6912,3323.077,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.756380,2081,9351,7,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756415,1856,9357,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756452,1632,9368,,,,,,,,,,256,156.863,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.756474,1632,9373,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756506,2688,9379,144,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756531,2240,9390,,,,,,,,,,147456,65828.571,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.756549,2336,9395,144,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756564,2048,9401,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756603,1632,9412,,,,,,,,,,256,156.863,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.756622,1664,9417,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756637,2976,9423,288,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756658,2464,9434,,,,,,,,,,294912,119688.312,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.756676,2560,9439,288,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756700,2047,9445,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756721,1760,9456,,,,,,,,,,512,290.909,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.756739,1729,9461,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.756753,3487,9467,576,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757191,2752,9482,,,,,,,,,,589824,214325.581,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.757246,2944,9487,576,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757270,1920,9493,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757311,1760,9504,,,,,,,,,,512,290.909,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.757329,1697,9509,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757363,5216,9515,1152,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757420,3648,9526,,,,,,,,,,1179648,323368.421,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.757457,3520,9531,1152,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757474,2080,9537,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757514,1792,9548,,,,,,,,,,1024,571.429,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.757533,1696,9553,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757547,6368,9559,2304,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757569,4704,9570,,,,,,,,,,2359296,501551.020,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.757606,4672,9575,2304,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757622,2048,9581,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757643,1760,9592,,,,,,,,,,1024,581.818,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.757660,1696,9597,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757674,11360,9603,4608,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757711,7647,9614,,,,,,,,,,4718592,617051.393,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.757743,7008,9619,4608,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757767,2463,9625,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757811,1984,9636,,,,,,,,,,2048,1032.258,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.757832,2048,9641,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757848,23872,9647,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757874,10048,9658,,,,,,,,,,9437184,939210.191,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.757899,14400,9663,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757915,2400,9669,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757946,1952,9680,,,,,,,,,,2048,1049.180,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.757964,2016,9685,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.757994,24703,9691,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.758021,11264,9702,,,,,,,,,,9437184,837818.182,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.758037,13185,9707,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.758054,2431,9713,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.758089,1920,9724,,,,,,,,,,2048,1066.667,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.758127,1952,9729,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.758146,24864,9735,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.758180,12224,9746,,,,,,,,,,9437184,772020.942,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.758224,14400,9751,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.758248,2432,9757,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.758273,1952,9768,,,,,,,,,,2048,1049.180,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.758303,1984,9773,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.758319,892450,9779,401408,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.759213,626018,9794,,,,,,,,,,411041792,656597.401,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.759841,891139,9799,401408,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.760733,3328,9805,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.760738,2145,9816,,,,,,,,,,16384,7638.228,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.760741,2049,9821,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.760745,150176,9827,65536,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.760896,103904,9838,,,,,,,,,,67108864,645873.730,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.761002,149633,9843,65536,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.761153,2784,9849,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.761157,2144,9860,,,,,,,,,,16384,7641.791,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.761160,2080,9865,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.761163,40544,9871,16000,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.761205,21632,9882,,,,,,,,,,16384000,757396.450,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.761228,31648,9887,16000,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.761261,2752,9893,4,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.761265,1952,9904,,,,,,,,,,4000,2049.180,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.761269,2016,9909,4,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.761280,4736,9915,,,,,,,,,,4,0.845,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
15.761363,3040,9922,,,,,,,,,,4,1.316,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
15.761419,2432,9929,,,,,,,,,,4,1.645,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
15.761448,2368,9936,,,,,,,,,,4,1.689,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
