Start(sec),Duration(nsec),CorrId,GrdX,GrdY,GrdZ,BlkX,BlkY,BlkZ,Reg/Trd,StcSMem,DymSMem,Bytes,Thru(MB/s),SrcMemKd,DstMemKd,Device,Ctx,Strm,Name
13.298779,3232,132,,,,,,,,,,6912,2138.614,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.299213,2144,144,,,,,,,,,,256,119.403,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.299391,16544,156,,,,,,,,,,147456,8912.959,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.299504,2112,168,,,,,,,,,,256,121.212,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.299646,27552,180,,,,,,,,,,294912,10703.833,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.299742,2176,192,,,,,,,,,,512,235.294,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.299939,51712,204,,,,,,,,,,589824,11405.941,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.300060,2176,216,,,,,,,,,,512,235.294,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.300721,103552,232,,,,,,,,,,1179648,11391.842,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.301044,2208,244,,,,,,,,,,1024,463.768,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.301364,345761,256,,,,,,,,,,2359296,6823.488,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.302041,2784,268,,,,,,,,,,1024,367.816,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.302350,351169,280,,,,,,,,,,2359296,6718.406,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.303001,2240,292,,,,,,,,,,1024,457.143,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.303354,346337,304,,,,,,,,,,2359296,6812.140,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.303882,3136,316,,,,,,,,,,1024,326.531,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.304196,943203,328,,,,,,,,,,4718592,5002.732,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.305457,2656,340,,,,,,,,,,2048,771.084,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.306107,2046087,356,,,,,,,,,,9437184,4612.308,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.308552,3200,368,,,,,,,,,,2048,640.000,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.308919,2073542,380,,,,,,,,,,9437184,4551.238,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.311252,2240,392,,,,,,,,,,2048,914.286,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.311924,2063814,408,,,,,,,,,,9437184,4572.691,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.314242,2208,420,,,,,,,,,,2048,927.536,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.314592,2042246,432,,,,,,,,,,9437184,4620.983,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.317029,2368,444,,,,,,,,,,2048,864.865,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.317667,2040487,460,,,,,,,,,,9437184,4624.966,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.320013,2304,472,,,,,,,,,,2048,888.889,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.320351,2057318,484,,,,,,,,,,9437184,4587.129,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.322857,2304,496,,,,,,,,,,2048,888.889,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.323473,2071879,512,,,,,,,,,,9437184,4554.891,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.325819,2336,524,,,,,,,,,,2048,876.712,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.326876,95920676,540,,,,,,,,,,411041792,4285.226,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.424051,7009,552,,,,,,,,,,16384,2337.566,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.424889,15546895,568,,,,,,,,,,67108864,4316.544,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.441028,6912,580,,,,,,,,,,16384,2370.370,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.441738,3692524,596,,,,,,,,,,16384000,4437.073,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
13.445878,4160,608,,,,,,,,,,4000,961.538,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.673311,1566884,643,,,,,,,,,,9633792,6148.376,Pinned,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.674886,8096,655,,,,,,,,,,128,15.810,Pinned,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.696619,2400,818,,,,,,,,,,20736,8640.000,Device,,NVIDIA A100-SXM4-40GB (0),1,21,[CUDA memset]
15.696669,2144,819,,,,,,,,,,20736,9671.642,Device,,NVIDIA A100-SXM4-40GB (0),1,22,[CUDA memset]
15.696683,2208,820,,,,,,,,,,20736,9391.304,Device,,NVIDIA A100-SXM4-40GB (0),1,23,[CUDA memset]
15.696745,2176,821,,,,,,,,,,20736,9529.412,Device,,NVIDIA A100-SXM4-40GB (0),1,24,[CUDA memset]
15.698043,5632,862,,,,,,,,,,112,19.886,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.756298,541634,2572,25088,2,1,8,8,1,64,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)"
15.756842,364513,2577,200704,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.757208,298369,2583,200704,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.759282,321441,2604,1568,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.759605,5120,2606,1,2,64,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.759613,961731,2610,1,3136,1,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)"
15.760577,364513,2617,200704,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.760943,300225,2623,200704,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.761246,275937,2632,50176,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.762916,77089,2648,392,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.762994,4865,2650,1,2,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.763043,360929,2654,1,1568,1,128,1,1,236,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.763407,185952,2661,100352,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.763595,151264,2667,100352,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.764454,152128,2688,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.764609,5409,2690,1,4,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.764617,615906,2694,1,1568,1,128,1,1,236,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.765235,185153,2701,100352,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.765422,149472,2707,100352,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.765574,143553,2716,25088,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.765720,40128,2728,98,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.765761,8544,2730,1,4,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.765772,332865,2734,2,392,1,128,1,1,236,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.766107,95424,2741,50176,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.766205,76224,2747,50176,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.766617,78944,2768,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.766698,11392,2770,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.766745,630818,2774,2,196,1,256,1,1,252,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.767378,96160,2781,50176,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.767476,75904,2787,50176,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.767554,79328,2804,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.767635,10848,2806,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.767647,624769,2810,2,196,1,256,1,1,252,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.768274,95968,2817,50176,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.768372,75552,2823,50176,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.768450,77280,2840,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.768528,10912,2842,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.768542,623649,2846,2,196,1,256,1,1,252,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.769167,95361,2853,50176,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.769265,76097,2859,50176,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.769343,75488,2868,12544,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.769420,19296,2884,25,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.769442,16224,2886,1,8,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.769461,320833,2890,4,49,1,256,1,1,252,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.769784,49248,2897,25088,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.769835,26496,2903,25088,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.770097,36128,2924,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.770135,30401,2926,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.770169,597953,2930,4,49,1,256,1,1,252,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.770769,49089,2937,25088,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.770820,26849,2943,25088,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.770849,35392,2960,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.770886,29152,2962,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.770917,597601,2966,4,49,1,256,1,1,252,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.771517,49377,2973,25088,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.771568,27136,2979,25088,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.771597,35680,2996,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.771635,29792,2998,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.771667,595714,3002,4,49,1,256,1,1,252,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.772264,48928,3009,25088,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.772315,27040,3015,25088,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.772345,36832,3024,6272,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.772384,10240,3036,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.772396,28448,3038,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.772427,172481,3042,4,25,1,128,1,1,252,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.772602,15040,3049,6272,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.772619,8352,3055,6272,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.772677,8416,3068,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.772687,28736,3070,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.772718,166113,3074,4,25,1,128,1,1,252,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.772888,14688,3081,6272,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.772905,8480,3087,6272,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.772994,8352,3100,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.773011,28704,3102,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.773042,165537,3106,4,25,1,128,1,1,252,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.773211,15040,3113,6272,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.773228,8512,3119,6272,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.773327,8288,3132,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.773346,29248,3134,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.773377,167457,3138,4,25,1,128,1,1,252,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.773549,14528,3145,6272,1,1,64,1,1,22,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.773565,8352,3151,6272,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.773575,9664,3160,1568,1,1,256,1,1,24,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)"
15.773786,52864,3172,8192,1,1,32,8,1,40,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::adaptive_average_pool<float>(float*, float*, int, int, int, int, long, long, long)"
15.774314,4512,3179,256,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.774479,4513,3200,,,,,,,,,,112,24.817,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.778168,4832,4867,,,,,,,,,,128,26.490,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.778223,354177,4870,8,4,3,128,1,1,164,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_32x6_tn_align4>(cutlass_80_tensorop_s1688gemm_128x64_32x6_tn_align4::Params)
15.778579,2848,4877,256,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.778671,4384,4904,256,1,1,256,1,1,31,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<unsigned char, unsigned int>, unsigned int, float, at::PhiloxCudaState)"
15.778789,4640,4911,256,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.778900,62240,4922,8,2,4,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x64_32x3_tn_align4>(cutlass_80_tensorop_s1688gemm_256x64_32x3_tn_align4::Params)
15.778964,4480,4924,512,1,1,128,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
15.778991,2656,4931,256,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl(at::TensorIterator&, c10::Scalar)::{lambda()#1}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)"
15.779462,4384,4962,256,1,1,256,1,1,31,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<unsigned char, unsigned int>, unsigned int, float, at::PhiloxCudaState)"
15.779566,4160,4969,63,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.779661,20160,4980,8,2,5,128,1,1,96,0,98304,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4>(cutlass_80_tensorop_s1688gemm_64x64_32x6_tn_align4::Params)
15.779683,3617,4982,125,1,1,128,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
15.780002,4832,4992,4,1,1,32,4,1,80,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)"
15.783791,4672,5005,1,1,1,32,1,1,34,256,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)"
15.784145,22176,5013,16,1,1,1024,1,1,32,128,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::gatherTopK<float, unsigned int, 2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, unsigned int, unsigned int, at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, at::cuda::detail::TensorInfo<long, unsigned int>, unsigned int)"
15.784250,8256,5016,16,1,1,16,1,1,25,416,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::bitonicSortKVInPlace<float, long, 2, -1, GTComp<float, true>, unsigned int, 32>(at::cuda::detail::TensorInfo<float, unsigned int>, unsigned int, unsigned int, unsigned int, at::cuda::detail::TensorInfo<long, unsigned int>, unsigned int, GTComp<float, true>)"
15.784524,2912,5029,1,1,1,64,1,1,26,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::CompareEqFunctor<long>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::CompareEqFunctor<long>, at::detail::Array<char*, 3>, OffsetCalculator<2, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)"
15.784686,3808,5040,1,1,1,64,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast)"
15.784888,4000,5053,1,1,1,16,1,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.785092,1760,5059,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.785168,2688,5070,1,1,1,64,1,1,18,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#22}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#22}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)"
15.785273,2815,5083,1,1,1,64,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithCast<1>, at::detail::Array<char*, 2>::StoreWithCast)"
15.785323,3296,5096,1,1,1,64,1,1,28,16,256,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.785355,1536,5102,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.785450,6560,5109,,,,,,,,,,4,0.610,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
15.785600,1535,5119,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.785692,1600,5126,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2>)"
15.785767,1536,5132,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.785802,1536,5141,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.785821,1536,5148,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<float> >, at::detail::Array<char*, 2>)"
15.785839,1536,5154,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)"
15.786241,1440,5166,1,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.787633,2240,5178,,,,,,,,,,64000,28571.429,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.787683,2976,5182,1,1,1,32,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)"
15.787794,5504,5194,4,1,1,32,4,1,107,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)"
15.787985,4480,5220,,,,,,,,,,112,25.000,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.791700,21024,6888,8,8,1,128,1,1,106,0,98304,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4>(cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4::Params)
15.791874,22464,6899,32,32,1,256,1,1,57,16384,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x32_nt
15.791986,5856,6910,2,1,1,32,4,1,52,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.792171,3136,6926,256,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3>)"
15.792297,3040,6934,256,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.792433,68321,6950,8,2,4,128,1,1,234,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x64_32x3_nn_align4>(cutlass_80_tensorop_s1688gemm_256x64_32x3_nn_align4::Params)
15.792503,3840,6952,512,1,1,128,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*, float const*)"
15.792972,59616,6967,32,64,1,128,1,1,122,12288,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x64_nt
15.793047,6976,6978,8,1,1,32,4,1,52,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.793127,3168,6994,256,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<float, float>(at::Tensor&, at::Tensor, at::Tensor, float)::{lambda(float, unsigned char)#1}, at::detail::Array<char*, 3>)"
15.793163,3104,7002,256,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.793301,316193,7017,8,25,1,128,1,1,156,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_32x6_nn_align4>(cutlass_80_tensorop_s1688gemm_128x64_32x6_nn_align4::Params)
15.794156,319874,7031,196,64,1,128,1,1,122,12288,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,ampere_sgemm_128x64_nt
15.794477,5951,7042,8,1,1,32,4,1,52,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.794485,3424,7062,1568,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.794490,40256,7067,8192,1,1,32,8,1,30,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::atomic_adaptive_average_gradinput<float>(float*, float*, int, int, int, int)"
15.794532,7744,7077,6272,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.794542,40512,7084,1,16,512,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.794584,10912,7092,6272,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.794598,25184,7106,32,1,1,32,16,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.796384,2400,7157,,,,,,,,,,20736,8640.000,Device,,NVIDIA A100-SXM4-40GB (0),1,33,[CUDA memset]
15.796399,2175,7158,,,,,,,,,,20736,9533.793,Device,,NVIDIA A100-SXM4-40GB (0),1,34,[CUDA memset]
15.796408,2145,7159,,,,,,,,,,20736,9667.133,Device,,NVIDIA A100-SXM4-40GB (0),1,35,[CUDA memset]
15.796424,2207,7160,,,,,,,,,,20736,9395.560,Device,,NVIDIA A100-SXM4-40GB (0),1,36,[CUDA memset]
15.796540,4512,7191,,,,,,,,,,112,24.823,Pageable,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy HtoD]
15.801941,29632,8865,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.801972,9792,8867,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.802023,181281,8871,4,25,1,128,1,1,254,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.807411,11424,8892,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.807426,12960,8894,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.807451,7104,8896,,,,,,,,,,9438368,1328599.099,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.807480,4128,8897,,,,,,,,,,1152,279.070,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.807538,204385,8900,36,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.807745,26528,8904,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.807774,16256,8915,6272,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.807792,25600,8929,32,1,1,32,16,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.808107,29440,8948,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.808138,9376,8950,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.808149,180897,8954,4,25,1,128,1,1,254,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.808332,12384,8970,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.808347,12736,8972,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.808367,7424,8974,,,,,,,,,,9438368,1271331.897,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.808380,6752,8975,,,,,,,,,,1152,170.616,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.808392,203968,8978,36,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.808598,26368,8982,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.808627,16576,8993,6272,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.808646,25343,9007,32,1,1,32,16,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.808778,28832,9026,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.808809,9632,9028,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.808821,181761,9032,4,25,1,128,1,1,254,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.809006,11744,9048,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.809019,12992,9050,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.809035,7232,9052,,,,,,,,,,9438368,1305084.071,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.809047,4064,9053,,,,,,,,,,1152,283.465,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.809057,204128,9056,36,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.809263,26496,9060,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.809293,16255,9071,6272,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.809312,25184,9085,32,1,1,32,16,1,28,16,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.809357,29312,9104,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.809388,9312,9106,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.809399,181536,9110,4,25,1,128,1,1,254,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 32, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)"
15.809584,12287,9126,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.809598,12767,9128,7,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.809613,7136,9130,,,,,,,,,,9438368,1322641.256,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.809627,4992,9131,,,,,,,,,,1152,230.769,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.809637,203201,9134,36,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.809843,26400,9138,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.809872,25824,9151,25088,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.809899,139457,9158,4,16,512,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.810075,53696,9170,25088,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.810139,34592,9183,512,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.811480,28993,9206,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.811511,37632,9208,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.811578,611489,9212,2,98,1,256,1,1,242,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.812376,37312,9232,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.812415,40832,9234,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.812458,8288,9236,,,,,,,,,,9438368,1138799.228,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.812470,4672,9237,,,,,,,,,,1152,246.575,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.812481,727363,9240,36,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.813210,27104,9244,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.813240,59008,9255,25088,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.813302,35936,9268,512,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.813340,28672,9287,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.813370,36416,9289,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.813409,611394,9293,2,98,1,256,1,1,242,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.814023,37536,9309,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.814063,40576,9311,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.814106,7360,9313,,,,,,,,,,9438368,1282386.957,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.814121,4256,9314,,,,,,,,,,1152,270.677,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.814132,727203,9317,36,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.814861,26881,9321,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.814891,58881,9332,25088,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.814952,36128,9345,512,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.814990,28384,9364,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.815020,36768,9366,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.815059,612546,9370,2,98,1,256,1,1,242,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.815674,37856,9386,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.815713,40672,9388,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.815756,7488,9390,,,,,,,,,,9438368,1260465.812,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.815772,4256,9391,,,,,,,,,,1152,270.677,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.815783,727427,9394,36,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.816513,26880,9398,1,16,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.816541,58816,9409,25088,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.816603,36192,9422,512,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.816641,16800,9441,1,8,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.816660,34272,9443,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.816698,314529,9447,1,98,1,256,1,1,242,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 256, 32, 2, 4, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.817016,19392,9463,25,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.817036,40352,9465,25,16,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.817079,5088,9467,,,,,,,,,,4719200,927515.723,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.817089,5856,9468,,,,,,,,,,576,98.361,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.817100,373536,9471,18,4,3,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.817476,15233,9475,1,8,512,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.817494,49440,9488,50176,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.817545,259168,9495,13,16,256,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.817806,110816,9503,50176,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.817920,62752,9516,256,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.817985,10144,9535,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.817996,67104,9537,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.818066,620802,9541,2,392,1,128,1,1,238,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.818688,74304,9561,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.818764,76193,9563,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.818842,3616,9565,,,,,,,,,,2359616,652548.673,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.818852,4352,9566,,,,,,,,,,288,66.176,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.818862,727906,9569,18,2,6,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.819592,9248,9573,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.819605,105792,9584,50176,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.819713,62689,9597,256,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.819778,9984,9616,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.819790,66433,9618,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.819859,619970,9622,2,392,1,128,1,1,238,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.820481,74177,9638,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.820557,76032,9640,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.820635,3552,9642,,,,,,,,,,2359616,664306.306,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.820647,4128,9643,,,,,,,,,,288,69.767,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.820658,728802,9646,18,2,6,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.821388,9247,9650,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.821400,106080,9661,50176,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.821508,63520,9674,256,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.821574,9984,9693,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.821586,67104,9695,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.821656,621090,9699,2,392,1,128,1,1,238,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.822280,74432,9715,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.822356,75809,9717,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.822434,3520,9719,,,,,,,,,,2359616,670345.455,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.822444,4063,9720,,,,,,,,,,288,70.884,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.822455,727875,9723,18,2,6,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.823185,9216,9727,1,8,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.823197,106016,9738,50176,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.823306,62465,9751,256,1,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.823370,7200,9770,1,4,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.823379,65697,9772,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.823448,339489,9776,1,196,1,256,1,1,254,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 128, 32, 4, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 3>::Params)"
15.823791,37408,9792,98,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.823831,76192,9794,98,8,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.823909,9504,9796,,,,,,,,,,12977024,1365427.609,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.823923,4096,9797,,,,,,,,,,864,210.938,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.823933,369345,9800,9,2,12,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.824305,17216,9802,9,2,4,128,1,1,64,0,17408,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.824324,6016,9805,1,4,256,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.824332,96577,9818,100352,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.824431,507905,9825,49,16,128,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.824941,223873,9833,100352,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.825169,5056,9848,,,,,,,,,,512,101.266,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.825180,115424,9850,128,4,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.825298,4992,9869,1,4,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.825304,142432,9871,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.825449,627586,9875,1,1568,1,128,1,1,238,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)"
15.826079,151104,9895,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.826231,156769,9897,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.826391,9792,9899,,,,,,,,,,13566848,1385503.268,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.826405,4640,9900,,,,,,,,,,864,186.207,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.826416,717666,9903,9,1,24,128,1,1,244,0,65536,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.827135,28992,9905,9,1,4,128,1,1,64,0,17408,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)"
15.827168,4320,9908,1,4,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.827174,219233,9919,100352,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.827397,6848,9934,,,,,,,,,,512,74.766,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.827410,114880,9936,128,4,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.827527,4928,9955,1,2,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.827533,142368,9957,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.827678,457922,9961,1,784,1,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.828138,75872,9977,392,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.828216,151361,9979,392,4,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.828370,4000,9981,,,,,,,,,,3244496,811124.000,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.828382,4608,9982,,,,,,,,,,432,93.750,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.828392,497057,9985,9,1,12,128,1,1,205,0,147456,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 3> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 3>::Params)"
15.828891,4192,9989,1,2,128,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.828898,192257,10002,200704,1,1,64,1,1,16,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)"
15.829093,1011107,10009,196,16,64,256,1,1,32,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)"
15.830106,445378,10021,200704,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.830556,4064,10036,,,,,,,,,,256,62.992,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.830567,215585,10038,64,7,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.830785,4544,10057,1,2,64,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.830790,308193,10059,1568,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.831102,1003747,10063,1,3136,1,128,1,1,255,0,122880,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 32, 256> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 256, 64, 32, 4, 1, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 3>::Params)"
15.832108,318113,10083,1568,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.832427,320929,10085,1568,2,16,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)"
15.832752,2976,10087,,,,,,,,,,1622480,545188.172,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.832759,6912,10088,,,,,,,,,,432,62.500,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.832771,1373988,10091,9,1,12,128,1,1,128,0,131072,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 64, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 64, 64> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 64, 64, 64, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 64, 64> >, false, 4>::Params)"
15.834148,3936,10095,1,2,64,256,1,1,32,4224,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)"
15.834157,434081,10106,200704,1,1,64,1,1,19,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIteratorBase&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)"
15.834595,4032,10121,,,,,,,,,,256,63.492,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.834606,214816,10123,64,7,1,32,16,1,28,16,2048,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)"
15.834822,2272,10144,,,,,,,,,,6912,3042.254,Device,,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memset]
15.834827,495842,10145,1,2,1568,8,8,1,80,2304,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)"
15.846588,2656,10163,7,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.846721,2080,10174,,,,,,,,,,6912,3323.077,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.846854,2080,10179,7,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.846882,2048,10185,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.846923,1600,10196,,,,,,,,,,256,160.000,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.846967,1664,10201,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.846985,2752,10207,144,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847011,2337,10218,,,,,,,,,,147456,63096.277,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.847038,2273,10223,144,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847055,2016,10229,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847085,1664,10240,,,,,,,,,,256,153.846,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.847103,1664,10245,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847119,3008,10251,288,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847150,2496,10262,,,,,,,,,,294912,118153.846,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.847169,2592,10267,288,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847183,2016,10273,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847203,1632,10284,,,,,,,,,,512,313.725,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.847219,1696,10289,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847243,3520,10295,576,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847804,2880,10310,,,,,,,,,,589824,204800.000,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.847865,2912,10315,576,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847887,1888,10321,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847917,1632,10332,,,,,,,,,,512,313.725,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.847945,1696,10337,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847961,4640,10343,1152,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.847995,4032,10354,,,,,,,,,,1179648,292571.429,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848024,3520,10359,1152,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848051,2240,10365,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848079,1791,10376,,,,,,,,,,1024,571.748,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848101,1728,10381,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848126,6240,10387,2304,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848161,4704,10398,,,,,,,,,,2359296,501551.020,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848181,4672,10403,2304,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848195,2048,10409,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848215,1792,10420,,,,,,,,,,1024,571.429,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848240,1696,10425,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848257,6368,10431,2304,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848276,4608,10442,,,,,,,,,,2359296,512000.000,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848298,4736,10447,2304,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848311,2080,10453,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848340,1664,10464,,,,,,,,,,1024,615.385,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848358,1696,10469,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848372,7200,10475,2304,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848392,4384,10486,,,,,,,,,,2359296,538160.584,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848407,4672,10491,2304,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848429,2048,10497,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848459,1760,10508,,,,,,,,,,1024,581.818,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848476,1664,10513,1,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848495,13120,10519,4608,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848520,7296,10530,,,,,,,,,,4718592,646736.842,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848542,7040,10535,4608,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848557,2400,10541,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848577,1952,10552,,,,,,,,,,2048,1049.180,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848593,2048,10557,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848607,24384,10563,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848633,11263,10574,,,,,,,,,,9437184,837892.569,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848655,14177,10579,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848676,2240,10585,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848694,2016,10596,,,,,,,,,,2048,1015.873,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848727,2049,10601,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848761,24608,10607,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848789,10976,10618,,,,,,,,,,9437184,859801.749,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848806,13664,10623,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848822,2368,10629,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848853,1984,10640,,,,,,,,,,2048,1032.258,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848870,2016,10645,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848884,24992,10651,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848916,11360,10662,,,,,,,,,,9437184,830738.028,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848929,13312,10667,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848953,2432,10673,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.848972,1984,10684,,,,,,,,,,2048,1032.258,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.848988,2017,10689,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849002,25055,10695,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849028,11008,10706,,,,,,,,,,9437184,857302.326,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.849046,13312,10711,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849060,2368,10717,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849082,1984,10728,,,,,,,,,,2048,1032.258,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.849097,2016,10733,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849111,24672,10739,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849137,9888,10750,,,,,,,,,,9437184,954407.767,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.849155,14432,10755,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849174,2432,10761,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849189,1952,10772,,,,,,,,,,2048,1049.180,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.849204,2016,10777,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849218,24832,10783,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849249,11200,10794,,,,,,,,,,9437184,842605.714,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.849267,13344,10799,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849282,2400,10805,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849299,1952,10816,,,,,,,,,,2048,1049.180,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.849314,2015,10821,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849328,24895,10827,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849361,11585,10838,,,,,,,,,,9437184,814603.712,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.849375,13248,10843,9216,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849392,2560,10849,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849406,1952,10860,,,,,,,,,,2048,1049.180,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.849428,2016,10865,2,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.849453,891619,10871,401408,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.850347,626049,10886,,,,,,,,,,411041792,656564.889,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.850974,888963,10891,401408,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.851865,2752,10897,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.851869,2144,10908,,,,,,,,,,16384,7641.791,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.851873,2080,10913,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.851877,149505,10919,65536,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.852029,104096,10930,,,,,,,,,,67108864,644682.447,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.852134,149088,10935,65536,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.852285,2720,10941,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.852289,2016,10952,,,,,,,,,,16384,8126.984,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.852292,2080,10957,16,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.852296,40673,10963,16000,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.852338,21888,10974,,,,,,,,,,16384000,748538.012,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.852362,29728,10979,16000,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.852393,2592,10985,4,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.852397,2112,10996,,,,,,,,,,4000,1893.939,Device,Device,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoD]
15.852401,2016,11001,4,1,1,64,1,1,20,0,0,,,,,NVIDIA A100-SXM4-40GB (0),1,7,"void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)"
15.852409,7776,11007,,,,,,,,,,4,0.514,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
15.852495,6720,11014,,,,,,,,,,4,0.595,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
15.852559,4225,11021,,,,,,,,,,4,0.947,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
15.852595,4353,11028,,,,,,,,,,4,0.919,Device,Pageable,NVIDIA A100-SXM4-40GB (0),1,7,[CUDA memcpy DtoH]
